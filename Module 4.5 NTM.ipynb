{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4.5 - Neural Turing Machines\n",
    "\n",
    "link to original post: https://blog.wtf.sg/2014/10/27/neural-turing-machines-a-first-look/\n",
    "\n",
    "link to original paper: https://arxiv.org/pdf/1410.5401.pdf\n",
    "\n",
    "##### Note: This is not a completed project: the forward pass is implemented compeletly, but the backward pass is still flawed. I will return to this project soon.\n",
    "\n",
    "## Introduction\n",
    "Neural Turing Machines were proposed by Google DeepMind in 2014. They speicalize in finding sequential patterns, like RNNs and LSTMs. \n",
    "\n",
    "## Theory\n",
    "### Architecture\n",
    "NTMs are consisted of two major compoents: a neural network controller and a memory bank. The controller interacts with in the input and produce output like common NNs, but in addition, they also interact with the memeory bank through read/write hands. On the highest level, they look like this: \n",
    "![NTM Architecture](https://blog.wtf.sg/wp-content/uploads/2014/10/Screenshot-from-2014-10-30-125035.png)\n",
    "\n",
    "### Memory Bank \n",
    "The memory bank is a matrix sized $(N * M)$. Where M_t is the content being focused on at time step t. \n",
    "\n",
    "### Reading\n",
    "Reading in NTMs are done in a differentiable fashion. In particular, they read blurrily. The read head emit a weight matrix at timestep t, w_t. The weights are normalized so all the elements sum to 1 and ranging (0,1). The *read column vector* (r_t) is the convex combination of w_t and M_t. \n",
    "\n",
    "### Writing\n",
    "The write head emits three vectors: a weight column vector (w_t), an erase row vector (e_t) and an add row vector (a_t). All three are in the range (0,1). \n",
    "\n",
    "The writing is consisted of two parts: an erase followed by an add. The steps are as follow: \n",
    "1. modify $M_t-1(i)$ by $M_t(i) ← M_t−1(i) * (1 − w_t(i) * e_t)$ where the multiplication is point wise.\n",
    "2. modify $M_t(i)$ by $M_t(i) ← M_t(i) + w_t(i) * a_t$\n",
    "\n",
    "The process of multiplying $w_t(i) * a_t$ and $w_t(i) * e_t$ can be intuitivly understood as: find some rows to focus on (where w(i) ~= 1.0) and change the content by $a_t$ and $e_t$. \n",
    "\n",
    "Notice, since both multiplication and addition are communitive, it doesn't matter if we have multiply write heads. Doing erasing at the same time nor does it matter if they are adding at the same time. \n",
    "\n",
    "### Reading and writing numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/miniconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1120: UserWarning: Bad val \"$TEMPLATE_BACKEND\" on line #41\n",
      "\t\"backend      : $TEMPLATE_BACKEND\n",
      "\"\n",
      "\tin file \"/Users/macbook/.matplotlib/matplotlibrc\"\n",
      "\tKey backend: Unrecognized backend string \"$template_backend\": valid strings are [u'pgf', u'ps', u'Qt4Agg', u'GTK', u'GTKAgg', u'nbAgg', u'agg', u'cairo', u'MacOSX', u'GTKCairo', u'Qt5Agg', u'template', u'WXAgg', u'TkAgg', u'GTK3Cairo', u'GTK3Agg', u'svg', u'WebAgg', u'pdf', u'gdk', u'WX']\n",
      "  (val, error_details, msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory bank:\n",
      "[[ 1.  3.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  9.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  2.]]\n",
      "\n",
      "read vector: \n",
      "array([[  3.,   5.,   3.,   3.,  11.,   3.,   4.]])\n",
      "\n",
      "Erased memory bank: \n",
      "array([[ 0.5,  1.5,  0.5,  0.5,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5,  0.5,  4.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  1. ]])\n",
      "\n",
      "Added memory bank: \n",
      "array([[ 1.5,  2.5,  1.5,  1.5,  1.5,  1.5,  1.5],\n",
      "       [ 1.5,  1.5,  1.5,  1.5,  5.5,  1.5,  1.5],\n",
      "       [ 1.5,  1.5,  1.5,  1.5,  1.5,  1.5,  2. ]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "# Allow matplotlib to plot inside this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# memory bank\n",
    "M = np.ones((3,7))\n",
    "# add an unique signature to each row\n",
    "M[0,1] = 3\n",
    "M[1,4] = 9\n",
    "M[2,6] = 2\n",
    "\n",
    "print \"Memory bank:\"\n",
    "print M\n",
    "print \"\"\n",
    "\n",
    "# reading\n",
    "w_r = np.ones((3, 1))\n",
    "r = np.dot(w_r.T, M)\n",
    "print \"read vector: \\n\" + repr(r)\n",
    "print \"\"\n",
    "\n",
    "# writing\n",
    "# erase\n",
    "e = np.ones((1, 7)) * 0.5\n",
    "w_w = np.ones((3, 1))\n",
    "M_tel = np.multiply(M, (1 - np.dot(w_w, e)))\n",
    "print \"Erased memory bank: \\n\" + repr(M_tel)\n",
    "print \"\"\n",
    "\n",
    "# add\n",
    "a = np.ones((1, 7))\n",
    "M = M_tel + np.dot(w_w, a)\n",
    "print \"Added memory bank: \\n\" + repr(M)\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing Mechanisms\n",
    "Addressing help us to produce the weight vectors as described above. I will call those paramters that determine the addressing weightings \"configs\", and those weightings simply by \"weightings\".\n",
    "\n",
    "#### Content-addressing\n",
    "For each head: \n",
    "1. Produce a M-long key vector, $k_t$ and $beta_t$ (key-strength).\n",
    "2. Calculate the similiarities between the key and the memory matrix.\n",
    "3. Multiply similiarities with $beta_t$.\n",
    "3. Normalize the similiarities to produce content weight column vector $w^c_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim(a, b):\n",
    "    # check for same length vectors\n",
    "    assert len(a.shape) == 1\n",
    "    assert len(b.shape) == 1\n",
    "    assert a.shape[0] == b.shape[0]\n",
    "    # L2\n",
    "    a_bar = np.linalg.norm(a, ord = 2)\n",
    "    b_bar = np.linalg.norm(b, ord = 2)\n",
    "    # for computation stablility\n",
    "    eps = 1e-10\n",
    "    return np.dot(a, b) / (eps + a_bar * b_bar)\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=0, keepdims=True)\n",
    "\n",
    "def softplus(z):\n",
    "    return np.log(np.exp(z) + 1.0) + 1.0\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory bank:\n",
      "[[ 1.5  2.5  1.5  1.5  1.5  1.5  1.5]\n",
      " [ 1.5  1.5  1.5  1.5  5.5  1.5  1.5]\n",
      " [ 1.5  1.5  1.5  1.5  1.5  1.5  2. ]]\n",
      "\n",
      "Key vector: \n",
      "array([ 1.,  1.,  1.,  1.,  1.,  1.,  3.])\n"
     ]
    }
   ],
   "source": [
    "k = np.ones((7))\n",
    "k[6] = 3\n",
    "beta = 10\n",
    "\n",
    "print \"Memory bank:\"\n",
    "print M\n",
    "print \"\"\n",
    "print \"Key vector: \\n\" + repr(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Weight: \n",
      "array([[ 0.28527786],\n",
      "       [ 0.0579956 ],\n",
      "       [ 0.65672653]])\n"
     ]
    }
   ],
   "source": [
    "w_c = np.zeros((M.shape[0], 1))\n",
    "for n in range(M.shape[0]):\n",
    "    w_c[n] = sim(k, M[n, :]) * beta\n",
    "w_c = softmax(w_c)\n",
    "print \"Content Weight: \\n\" + repr(w_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre Location-addressing: interpolation gate\n",
    "Now the network will decide wether to use the last set of weights or use the current content weights, or in other words, wether to location address or content address.\n",
    "\n",
    "Each head will produce a scalar interpolation gate $g_t$ ranging $(0,1)$. If the gate is close to 1.0, the content vector will be used, otherwise the last weight will be used. However, it is done in a blending fashion. The output is the gated weights: $w^g_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gated Weights: \n",
      "array([[ 0.4996945 ],\n",
      "       [ 0.34059692],\n",
      "       [ 0.75970857]])\n"
     ]
    }
   ],
   "source": [
    "# use the write head as example\n",
    "g_t = 0.7\n",
    "w_g = g_t * w_c + (1.0 - g_t) * w_w\n",
    "print \"Gated Weights: \\n\" + repr(w_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location-addressing: circular convolution\n",
    "This is perhaps the hardest part of the model. It goes as following: \n",
    "\n",
    "For each head:\n",
    "1. emit shift weighting $s_t$, which defines a normalised distribution over the allowed integer shifts. For example, if shifts between $-1$ and $1$ are allowed, $s_t$ has three elements corresponding to the degree to which shifts of $-1$, $0$ and $1$ are performed.\n",
    "2. The convoluted weights are calculated (see code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift weighting: \n",
      "array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.]])\n"
     ]
    }
   ],
   "source": [
    "# shift by each index corrosponds to shifting by 0, 1, and -1\n",
    "s = np.array([[0.0, 1.0, 0.0]]).T\n",
    "print \"Shift weighting: \\n\" + repr(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted weights: \n",
      "array([[ 0.75970857],\n",
      "       [ 0.4996945 ],\n",
      "       [ 0.34059692]])\n"
     ]
    }
   ],
   "source": [
    "w_cc = np.zeros_like(w_g)\n",
    "N = w_g.shape[0]\n",
    "# circular convolution\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        w_cc[i] += w_g[j % N] * s[(i - j) % N]\n",
    "print \"Shifted weights: \\n\" + repr(w_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharpening\n",
    "Finally, in case of leakage, or in other words, when the weights are spread over, we can sharpen them and make them more focused on one location. \n",
    "\n",
    "The process is similiar to softmax, but instead of exp function, it uses a scalar emitted by each head $gamma_t$ as exponets, where $gamma_t > 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sharpen(z, gamma):\n",
    "    return np.power(z, gamma) / np.sum(np.power(z, gamma), axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: \n",
      "array([[ 0.87625486],\n",
      "       [ 0.10787434],\n",
      "       [ 0.0158708 ]])\n"
     ]
    }
   ],
   "source": [
    "gamma = 5\n",
    "w = sharpen(w_cc, gamma)\n",
    "print \"Weight: \\n\" + repr(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Three Modes of Addressing\n",
    "The combined addressing system of weighting interpolation and content and locationbased\n",
    "addressing can operate in three complementary modes. \n",
    "* One, pure content: a weighting can be chosen by the content system without any modification by the location system. \n",
    "* Two, random access: a weighting produced by the content addressing system can be chosen and then shifted. This allows the focus to jump to a location next to, but not on, an address accessed by content; in computational terms this allows a head to find a contiguous block of data, then access a particular element within that block. \n",
    "* Three, iterative access: weighting from the previous time step can be rotated without any input from the content-based addressing system. This allows the weighting to iterate through a sequence of addresses by advancing the same distance at each time-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Implementation\n",
    "### Memory Matrix\n",
    "The memory matrix is sized $(N * M)$ and initialized to all 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MemoryMatrix(object):\n",
    "    def __init__(self, N, M, random_init = False):\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        if random_init:\n",
    "            self.matrix = softmax(np.random.rand(M, N)).T\n",
    "        else:\n",
    "            self.matrix = np.zeros((N, M))\n",
    "            \n",
    "        self.grad = np.zeros_like(self.matrix)\n",
    "        self.matrices = []\n",
    "            \n",
    "    def archive(self):\n",
    "        self.matrices.append(np.copy(self.matrix))\n",
    "        \n",
    "    def get_last_archive(self):\n",
    "        return self.matrices[-1]\n",
    "    \n",
    "    def pop(self):\n",
    "        # make sure we have enough time crystals to time travel\n",
    "        assert len(self.matrices) > 0\n",
    "        return self.matrices.pop()\n",
    "    \n",
    "    def save_gradient(self, grad):\n",
    "        assert self.grad.shape == self.matrix.shape\n",
    "        self.grad += grad\n",
    "        \n",
    "    def get_gradient(self):\n",
    "        return self.grad\n",
    "    \n",
    "    def clear_grad(self):\n",
    "        self.grad = np.zeros_like(self.matrix)\n",
    "        \n",
    "    def clear_archive(self):\n",
    "        self.matrices = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heads\n",
    "Although the paper defined a \"head\" as the outputs of the controller network, it also seem appropriate if we extent their roles a bit. In particular, I think the job of calculating read vecctors and writing operations should be their role, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(object):\n",
    "    def __init__(self, memory_matrix, W_init):\n",
    "        self.matrix = memory_matrix.matrix\n",
    "        self.N = memory_matrix.N\n",
    "        self.M = memory_matrix.M\n",
    "        self.W = W_init\n",
    "        \n",
    "        ##### for backward prop #####\n",
    "        self.weightings = []\n",
    "        self.configs = []\n",
    "        \n",
    "    \n",
    "    def calculate_weights(self, K_hat, S_hat, g_hat, beta_hat, gamma_hat, e = None, a = None):\n",
    "        ##### calculate and save forward pass varibles here #####\n",
    "        self.K = K_hat\n",
    "        self.S = softmax(S_hat)\n",
    "        self.g = sigmoid(g_hat)\n",
    "        self.beta = np.exp(beta_hat)\n",
    "        self.gamma = softplus(gamma_hat)\n",
    "        # these are only for write vectors\n",
    "        self.a = a\n",
    "        self.e = e\n",
    "        \n",
    "        ##### do forward calculation here #####\n",
    "        w_c, sims = self.get_content_weightings()\n",
    "        \n",
    "        w_g = self.get_gated_weightings(w_c)\n",
    "        w_s = self.get_shift_weightings(w_g)\n",
    "        w = self.get_sharpened_weightings(w_s)\n",
    "        self.W = w\n",
    "        \n",
    "        ##### save weightings and configs for backprop #####\n",
    "        ## pack ##\n",
    "        weighting = (w_c, w_g, w_s, sims)\n",
    "        config = (self.K, self.S, self.g, self.beta, self.gamma)\n",
    "        ## save ##\n",
    "        self.weightings.append(weighting)\n",
    "        self.configs.append(config)\n",
    "    \n",
    "    # use weighting gradients to calculate config gradients\n",
    "    def get_config_grad(self, w_grad, matrix):\n",
    "        \n",
    "        ## retrive the variables for back prop ##\n",
    "        #assert len(self.weightings) > 1\n",
    "        #assert len(self.configs) > 1\n",
    "        w_c, w_g, w_s, sims = self.weightings.pop()\n",
    "        K, S, g, beta, gamma = self.configs.pop()\n",
    "        \n",
    "        ##### do backward calculation here #####\n",
    "        w_s_grad, gamma_grad = self.backprop_sharpened_weightings(w_grad, w_s, gamma)\n",
    "        w_g_grad, S_grad = self.backprop_shift_weightings(w_s_grad, w_g, S)\n",
    "        w_c_grad, g_grad = self.backprop_gated_weightings(w_g_grad, w_c, g)\n",
    "        K_grad, beta_grad = self.backprop_content_weightings(w_c_grad, beta, K, sims, matrix)\n",
    "        \n",
    "        # make sure shapes stay consistant\n",
    "        assert K_grad.shape == K.shape\n",
    "        assert S_grad.shape == S.shape\n",
    "        \n",
    "        return np.hstack([K_grad, S_grad, beta_grad, gamma_grad, g_grad])\n",
    "            \n",
    "    ##### helper methods #####\n",
    "    ## content: forward and backward pair ##\n",
    "    def get_content_weightings(self):\n",
    "        \n",
    "        assert len(self.K.shape) == 1\n",
    "        assert self.K.shape[0] == self.M\n",
    "        \n",
    "        w_c = np.zeros((self.N, 1))\n",
    "        sims = np.zeros((self.N, 1))\n",
    "        \n",
    "        for n in range(N):\n",
    "            sims[n] = sim(self.K, self.matrix[n, :])\n",
    "            w_c[n] = sims[n] * self.beta\n",
    "        w_c = self.softmax(w_c)\n",
    "        \n",
    "        return w_c, sims\n",
    "    \n",
    "    def backprop_content_weightings(self, outgrad, beta, K, sims, matrix):\n",
    "        ### calculate the softmax derivative\n",
    "        exp_term = np.exp(sims * beta)\n",
    "        sum_term = np.sum(exp_term)\n",
    "        power_term = exp_term ** 2\n",
    "        power_sum_term = sum_term ** 2\n",
    "        softmax_deriv = (exp_term * sum_term - power_term) / power_sum_term\n",
    "        \n",
    "        beta_grad = np.sum(np.multiply(outgrad, np.multiply(sims, softmax_deriv)))\n",
    "        sims_grad = np.multiply(outgrad, beta * softmax_deriv)\n",
    "        \n",
    "        ##### WARNING: I'm not going to calculate the matrix gradient\n",
    "        ##### WARNING: I'm going to use the lowest error to determine the error on the key\n",
    "        K_grad = K - matrix[np.argmin(sims_grad)]\n",
    "        \n",
    "        return K_grad, beta_grad\n",
    "    \n",
    "    ## gate: forward and backward pair ##\n",
    "    def get_gated_weightings(self, w_c):\n",
    "        \n",
    "        assert self.W.shape == w_c.shape\n",
    "        \n",
    "        w_g = self.g * w_c + (1.0 - self.g) * self.W\n",
    "        return w_g\n",
    "    \n",
    "    def backprop_gated_weightings(self, outgrad, w_c, g):\n",
    "        ##### WARNING: I'm not going to propagate error to the past weightings #####\n",
    "        ## I think some information will be lost here, but not ALL will be lost. \n",
    "        ## As long as the error on the gate config is passed back, I believe the model\n",
    "        ## will eventually converge. \n",
    "        w_c_grad = outgrad / g\n",
    "        g_grad = np.sum(outgrad / w_c)\n",
    "        \n",
    "        return w_c_grad, g_grad\n",
    "    \n",
    "    ## shift: forward and backward pair ##\n",
    "    def get_shift_weightings(self, w_g):\n",
    "        w_s = np.zeros_like(w_g)\n",
    "        # circular convolution\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                w_s[i] += w_g[j % self.N] * self.S[(i - j) % self.N]\n",
    "        return w_s\n",
    "\n",
    "    def backprop_shift_weightings(self, outgrad, w_g, S):\n",
    "        ### since shift configs are shifted at each row calculation\n",
    "        ##  let's shift them first\n",
    "        S_shifted = np.zeros((S.shape[0], S.shape[0]))\n",
    "        for i in range(S.shape[0]):\n",
    "            S_shifted[i] = np.roll(S, i)\n",
    "        w_g_grad = np.dot(S_shifted.T, outgrad)\n",
    "        \n",
    "        S_shifted_grad = np.dot(outgrad, w_g.T)\n",
    "        ## now roll the grads back to original shape\n",
    "        for i in range(S.shape[0]):\n",
    "            S_shifted[i] = np.roll(S_shifted[i], -i)\n",
    "            \n",
    "        S_grad = np.sum(S_shifted, axis = 0)\n",
    "        \n",
    "        return w_g_grad, S_grad\n",
    "        \n",
    "    ## sharpen: forward and backward pair ##\n",
    "    def get_sharpened_weightings(self, w_s):\n",
    "        w = self.sharpen(w_s, self.gamma)\n",
    "        return w\n",
    "    \n",
    "    def backprop_sharpened_weightings(self, outgrad, w_s, gamma):\n",
    "        ##### sharpen function's derivative terms #####\n",
    "        power_term = np.power(w_s, gamma)\n",
    "        power_sum_term = np.sum(power_term, axis=0, keepdims=True)\n",
    "        log_term = np.log(w_s)\n",
    "        log_sum_term = np.sum(log_term, axis=0, keepdims=True)\n",
    "        log_diff_term = log_term - log_sum_term\n",
    "        \n",
    "        ### getting the backprop grad\n",
    "        w_s_deriv = (power_sum_term - power_term) / (power_sum_term ** 2)\n",
    "        # chain rule\n",
    "        w_s_grad = np.multiply(outgrad, w_s_deriv)\n",
    "\n",
    "        ### getting the gamma grad\n",
    "        beta_grad = np.sum(np.multiply(outgrad, np.multiply(power_term, log_diff_term) / power_sum_term))\n",
    "        \n",
    "        return w_s_grad, beta_grad\n",
    "    \n",
    "    \n",
    "    ##### utils #####\n",
    "    def sim(self, a, b):\n",
    "        # check for same length vectors\n",
    "        assert len(a.shape) == 1\n",
    "        assert len(b.shape) == 1\n",
    "        assert a.shape[0] == b.shape[0]\n",
    "        # L2\n",
    "        a_bar = np.linalg.norm(a, ord = 2)\n",
    "        b_bar = np.linalg.norm(b, ord = 2)\n",
    "        # for computation stablility\n",
    "        eps = 1e-10\n",
    "        return np.dot(a, b) / (0.0 + a_bar * b_bar)\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        return np.exp(z) / np.sum(np.exp(z), axis=0, keepdims=True)\n",
    "    \n",
    "    def sharpen(self, z, gamma):\n",
    "        return np.power(z, gamma) / np.sum(np.power(z, gamma), axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Heads and Write Heads\n",
    "We will define read heads by inherenting the Head class. We will extend a interact_with_matrix method to return the read vector (read heads) or to manipulate matrix (write heads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadHead(Head):\n",
    "    def read(self):\n",
    "        r = np.dot(self.W.T, self.matrix)\n",
    "        # always make sure we get all the read outputs\n",
    "        assert r.shape[0] == 1\n",
    "        return r[0]\n",
    "    \n",
    "    # returns matrix gradients & head weighting gradients\n",
    "    # matrix_h is the historical version of the matrix\n",
    "    def backward(self, outgrad, matrix_h):\n",
    "        #assert len(outgrad.shape) == 1\n",
    "        #assert outgrad.shape[0] == self.M\n",
    "        assert outgrad.shape[1] == self.M\n",
    "        \n",
    "        # matrix grad is for write head to bptt\n",
    "        matrix_grad = np.dot(self.W, outgrad)\n",
    "        # w_grad is for read head config bptt\n",
    "        w_grad = np.dot(matrix_h, outgrad.T)\n",
    "        \n",
    "        return matrix_grad, w_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WriteHead(Head):\n",
    "    def erase(self):    \n",
    "        assert len(self.e.shape) == 2\n",
    "        assert self.e.shape[0] == 1\n",
    "        assert self.e.shape[1] == self.M\n",
    "        # modify the matrix, not change reference\n",
    "        self.matrix[:] = np.multiply(self.matrix, (1 - np.dot(self.W, self.e)))[:]\n",
    "        \n",
    "    def add(self):\n",
    "        assert len(self.a.shape) == 2\n",
    "        assert self.a.shape[0] == 1\n",
    "        assert self.a.shape[1] == self.M\n",
    "        # modify the matrix, not change reference\n",
    "        self.matrix[:] = (self.matrix + np.dot(self.W, self.a))[:]\n",
    "        \n",
    "    # takes the matrix grad after add, and matrix value before erase\n",
    "    # returns write weighting gradients, add vector gradients, and erase gradients\n",
    "    def backward(self, matrix_grad, matrix_h_e):\n",
    "        eps = 0.0001\n",
    "        a_grad = np.dot(self.W.T, matrix_grad)\n",
    "        # w_grad at add time\n",
    "        w_grad = np.dot(matrix_grad, self.a.T)\n",
    "        # matrix grad at add time is the same as matrix grad at erase time\n",
    "        # for erase grad, we need to rearrange the terms in erase equations first\n",
    "        matrix_grad /= - matrix_h_e + eps\n",
    "        ### What if it's the first iteration? Hence the matrix is all zeros? \n",
    "        ### That case we would encounter a division by 0 error\n",
    "        e_grad = np.dot(self.W.T, matrix_grad)\n",
    "        # add the w_grad at erase time on top of w_grad at add time\n",
    "        w_grad += np.dot(matrix_grad, self.e.T)\n",
    "        \n",
    "        return w_grad, a_grad, e_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controller\n",
    "We will calculate controller sizes using the number of heads, input size, output size, and memory matrix sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient clipping\n",
    "def clip(grad, min_g, max_g):\n",
    "    grad = np.minimum(grad, max_g)\n",
    "    grad = np.maximum(grad, min_g)\n",
    "    return grad\n",
    "\n",
    "def assert_clipped(grad, min_g, max_g):\n",
    "    assert (grad >= min_g).all()\n",
    "    assert (grad <= max_g).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a simple feedforward layer\n",
    "class Linear(object):\n",
    "    def __init__(self, W):\n",
    "        self.W = W\n",
    "        self.X = []\n",
    "        self.grad = np.zeros_like(self.W)\n",
    "        \n",
    "    def update(self, lr):\n",
    "        self.checkRep()\n",
    "        self.W -= self.grad * lr\n",
    "        self.grad = np.zeros_like(self.W)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # save for backprop thru time\n",
    "        self.X.append(X)\n",
    "        return np.dot(self.W.T, X)\n",
    "    \n",
    "    def backward(self, outgrad):\n",
    "        outgrad = clip(outgrad, -10, 10)\n",
    "        assert_clipped(outgrad, -10, 10)\n",
    "        # accumulate gradient\n",
    "        assert len(self.X) > 0\n",
    "\n",
    "        self.grad += np.dot(np.array([self.X.pop()]).T, np.array([outgrad]))\n",
    "        \n",
    "        return np.dot(self.W, outgrad)\n",
    "    \n",
    "    def checkRep(self):\n",
    "        assert self.grad.shape == self.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid(object):\n",
    "    def __init__(self):\n",
    "        self.Y = []\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # save for bptt\n",
    "        self.Y.append(sigmoid(X))\n",
    "        return self.Y[-1]\n",
    "    \n",
    "    def backward(self, outgrad):\n",
    "        # you can go back in time NO LONGERRRR!! (unfortunatly)\n",
    "        assert len(self.Y) > 0\n",
    "        \n",
    "        Y = self.Y.pop()\n",
    "        return Y * (1 - Y) * outgrad\n",
    "    \n",
    "    def update(self, lr):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Controller(object):\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        \n",
    "    def forward(self, X):\n",
    "        z = X\n",
    "        for n in self.graph: \n",
    "            z = n.forward(z)\n",
    "        return z\n",
    "    \n",
    "    def backward(self, outgrad):\n",
    "        grad = outgrad\n",
    "        for n in reversed(self.graph):\n",
    "            grad = n.backward(grad)\n",
    "        return grad\n",
    "    \n",
    "    def update(self, lr):\n",
    "        for n in self.graph:\n",
    "            n.update(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralTuringMachine(object):\n",
    "    def __init__(self, memory_matrix, controller, nb_of_w_heads, nb_of_r_heads):\n",
    "        self.N = memory_matrix.N\n",
    "        self.M = memory_matrix.M\n",
    "        # componets\n",
    "        self.controller = controller\n",
    "        self.matrix = memory_matrix.matrix\n",
    "        self.w_heads = []\n",
    "        self.r_heads = []\n",
    "        self.memory_matrix = memory_matrix\n",
    "        memory_matrix.archive()\n",
    "        \n",
    "        # mount the heads\n",
    "        for i in range(nb_of_w_heads):\n",
    "            self.w_heads.append(WriteHead(memory_matrix, np.random.uniform(0, 1, (self.N, 1))))\n",
    "        for i in range(nb_of_r_heads):\n",
    "            self.r_heads.append(ReadHead(memory_matrix, np.random.uniform(0, 1, (self.N, 1))))\n",
    "\n",
    "        self.r = np.zeros((self.M * nb_of_r_heads))\n",
    "        \n",
    "    def step_forward(self, X):\n",
    "        # for convience's sake\n",
    "        N = self.N\n",
    "        M = self.M\n",
    "        \n",
    "        # input + read vector\n",
    "        z = np.zeros((X.shape[0] + self.r.shape[0]))\n",
    "        z[:X.shape[0]] = X\n",
    "        z[X.shape[0]:] = self.r\n",
    "        \n",
    "        # forward through the controller\n",
    "        z = self.controller.forward(z)\n",
    "        \n",
    "        # write weights first\n",
    "        for h in self.w_heads:\n",
    "            z_split = np.split(z, [M, M * 2, M * 3, M * 3 + N, M * 3 + N + 1, M * 3 + N + 2, M * 3 + N + 3])\n",
    "            \n",
    "            e = np.array([z_split[0]])\n",
    "            a = np.array([z_split[1]])\n",
    "            \n",
    "            K = z_split[2]\n",
    "            S = z_split[3]\n",
    "            beta = z_split[4]\n",
    "            gamma = z_split[5]\n",
    "            g = z_split[6]\n",
    "            z = z_split[7]\n",
    "            \n",
    "            h.calculate_weights(K, S, g, beta, gamma, e, a)\n",
    "            \n",
    "            \n",
    "        # read weights second\n",
    "        for h in self.r_heads:\n",
    "            z_split = np.split(z, [M, M + N, M + N + 1, M + N + 2, M + N + 3])\n",
    "            \n",
    "            K = z_split[0]\n",
    "            S = z_split[1]\n",
    "            beta = z_split[2]\n",
    "            gamma = z_split[3]\n",
    "            g = z_split[4]\n",
    "            z = z_split[5]\n",
    "            \n",
    "            h.calculate_weights(K, S, g, beta, gamma)\n",
    "            \n",
    "            \n",
    "        # write to matrix\n",
    "        for h in self.w_heads:\n",
    "            h.erase()\n",
    "            h.add()\n",
    "            \n",
    "        # read matrix & update read vector\n",
    "        self.r = np.array([])\n",
    "        for h in self.r_heads:\n",
    "            self.r = np.hstack([self.r, h.read()])\n",
    "                                \n",
    "        ##### save the matrix right now \n",
    "        ##   (since we need to back prop thru time later)\n",
    "        self.memory_matrix.archive()\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    # backprop one timestep\n",
    "    # return the config gradients, aka the grads for one portion of the output of ontroller\n",
    "    def step_backward(self, outgrad):\n",
    "        grad = self.controller.backward(outgrad)\n",
    "        # read weighting grads\n",
    "        grad = grad[:self.r.shape[0]]\n",
    "        \n",
    "        config_grad = np.array([])\n",
    "        # we don't need this version of matrix anymore\n",
    "        matrix_h = self.memory_matrix.pop()\n",
    "        # we still need this version of matrix because \n",
    "        #   matrix before erase is the matrix after last read\n",
    "        #   which is what we need for for the next \n",
    "        matrix_h_e = self.memory_matrix.get_last_archive()\n",
    "        \n",
    "        # backprop read heads first\n",
    "        for h in self.r_heads:\n",
    "            grad_split = np.split(grad, [self.M])\n",
    "            \n",
    "            #### split for each head\n",
    "            h_grad = grad_split[0]\n",
    "            grad = grad_split[1]\n",
    "            \n",
    "            h_grad = np.array([h_grad])\n",
    "            \n",
    "            matrix_grad, w_grad = h.backward(h_grad, matrix_h)\n",
    "            # put this in the controller output style\n",
    "            config_grad = np.hstack([config_grad, h.get_config_grad(w_grad, matrix_h_e)])\n",
    "            # save it for later use\n",
    "            self.memory_matrix.save_gradient(matrix_grad)\n",
    "        \n",
    "        # back prop write heads\n",
    "        for h in reversed(self.w_heads):\n",
    "            w_grad, a_grad, e_grad = h.backward(self.memory_matrix.get_gradient(), matrix_h_e)\n",
    "            \n",
    "            # append in reverse order so it matched how input came in\n",
    "            config_grad = np.hstack([e_grad[0], a_grad[0], h.get_config_grad(w_grad, matrix_h_e), config_grad])\n",
    "        \n",
    "        # clear grad for next run\n",
    "        self.memory_matrix.clear_grad()\n",
    "        \n",
    "        return config_grad\n",
    "    \n",
    "    def update(self, lr):\n",
    "        self.controller.update(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Incremental Number Task - PASS\n",
    "We task the model by giving it an input from 0 - 5 encoded in one hot vector and ask what's the next increment.\n",
    "\n",
    "This can be achieved by simple feedforward NNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MemoryMatrix(7, 6, random_init = True)\n",
    "graph = [Linear(np.random.uniform(-1, 1, (6 + 6, 50))), Sigmoid(), Linear(np.random.uniform(-1, 1, (50, 70))), Sigmoid(), Linear(np.random.uniform(-1, 1, (70, 28*1 + 16*1 + 6))), Sigmoid()]\n",
    "con = Controller(graph)\n",
    "nb_of_w_heads = 1\n",
    "nb_of_r_heads = 1\n",
    "ntm = NeuralTuringMachine(m, con, nb_of_w_heads, nb_of_r_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 36.50it/s]\n"
     ]
    }
   ],
   "source": [
    "costs = []\n",
    "for _ in tqdm(range(100)):\n",
    "    Y = []\n",
    "    for i in range(12):\n",
    "        a = np.zeros((6))\n",
    "        a[i % 6] = 1\n",
    "        Y.append(ntm.step_forward(a))\n",
    "\n",
    "    config_grad = np.zeros(28*1 + 16*1)\n",
    "    for i in reversed(range(12)):\n",
    "        T = np.zeros((6))\n",
    "        T[(i + 1)% 6] = 1\n",
    "        \n",
    "        cost = Y[i] - T\n",
    "        costs.append(np.sum(abs(cost)))\n",
    "        grad = np.hstack([config_grad, cost])\n",
    "        config_grad = ntm.step_backward(grad)\n",
    "\n",
    "    ntm.update(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngYKCiIgU/H8dmBm6+nzV6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105fa9150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve\n",
    "plt.plot(costs, 'bo')\n",
    "plt.xlabel('itr')\n",
    "plt.ylabel('cost')\n",
    "plt.title('NTM Cost over time')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    test = np.zeros((6))\n",
    "    test[i] = 1\n",
    "    print np.argmax(ntm.step_forward(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Input Incremental Number Task - NO PASS\n",
    "This task is esstentially the same as above, but with a twist: the input is alwsys constant. So we are trying to see if the model can establish temporal dependency.\n",
    "\n",
    "This CANNOT be achieved by simple feedforward NNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = MemoryMatrix(7, 6, random_init = True)\n",
    "graph = [Linear(np.random.uniform(-1, 1, (6 + 6, 50))), Sigmoid(), Linear(np.random.uniform(-1, 1, (50, 70))), Sigmoid(), Linear(np.random.uniform(-1, 1, (70, 28*1 + 16*1 + 6))), Sigmoid()]\n",
    "con = Controller(graph)\n",
    "nb_of_w_heads = 1\n",
    "nb_of_r_heads = 1\n",
    "ntm = NeuralTuringMachine(m, con, nb_of_w_heads, nb_of_r_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:25<00:00, 68.66it/s]\n"
     ]
    }
   ],
   "source": [
    "costs = []\n",
    "for _ in tqdm(range(10000)):\n",
    "    Y = []\n",
    "    for i in range(6):\n",
    "        a = np.zeros((6))\n",
    "        #a[i % 6] = 1\n",
    "        Y.append(ntm.step_forward(a))\n",
    "\n",
    "    config_grad = np.zeros(28*1 + 16*1)\n",
    "    for i in reversed(range(6)):\n",
    "        T = np.zeros((6))\n",
    "        T[(i + 1)% 6] = 1\n",
    "        \n",
    "        cost = Y[i] - T\n",
    "        costs.append(np.sum(abs(cost)))\n",
    "        grad = np.hstack([config_grad, cost])\n",
    "        config_grad = ntm.step_backward(grad)\n",
    "        \n",
    "    ntm.update(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106c4f090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve\n",
    "plt.plot(costs, 'bo')\n",
    "plt.xlabel('itr')\n",
    "plt.ylabel('cost')\n",
    "plt.title('NTM Cost over time')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    test = np.zeros((6))\n",
    "    #test[(i) % 6] = 1\n",
    "    print np.argmax(ntm.step_forward(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal AND Task - NO PASS\n",
    "We task the model to perform ADD operation by giving it the operands sperately. This task helps us to whether evaluate can save data into its matrix and read it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "M = 1\n",
    "I = 1\n",
    "O = 1\n",
    "\n",
    "m = MemoryMatrix(2, 1, random_init = True)\n",
    "graph = [Linear(np.random.uniform(-1, 1, (M + I, 10))), Sigmoid(), Linear(np.random.uniform(-1, 1, (10, 10))), Sigmoid(), Linear(np.random.uniform(-1, 1, (10, (3 * M + N + 3)*1 + (M + N + 3)*1 + O))), Sigmoid()]\n",
    "con = Controller(graph)\n",
    "nb_of_w_heads = 1\n",
    "nb_of_r_heads = 1\n",
    "ntm = NeuralTuringMachine(m, con, nb_of_w_heads, nb_of_r_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:12<00:00, 52.01it/s]\n"
     ]
    }
   ],
   "source": [
    "costs = []\n",
    "config_grad = np.zeros((3 * M + N + 3)*1 + (M + N + 3)*1)\n",
    "for _ in tqdm(range(10000)):\n",
    "    \n",
    "    for _ in range(10):\n",
    "        a = np.random.randint(0, 2, (1))\n",
    "        b = np.random.randint(0, 2, (1))\n",
    "        if a[0] == 1 and b[0] == 1:\n",
    "            T = np.array([1])\n",
    "        else:\n",
    "            T = np.array([0])\n",
    "\n",
    "        ntm.step_forward(a)\n",
    "        Y = ntm.step_forward(b)\n",
    "\n",
    "        cost = Y - T\n",
    "        costs.append(np.sum(abs(cost)))\n",
    "\n",
    "        grad = np.hstack([config_grad, cost])\n",
    "        config_grad = ntm.step_backward(grad)\n",
    "\n",
    "        ntm.update(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUBARkRIFBRERKfn/n6aYCiXs+asAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1069c9e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve\n",
    "plt.plot(costs, 'bo')\n",
    "plt.xlabel('itr')\n",
    "plt.ylabel('cost')\n",
    "plt.title('NTM Cost over time')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63446824]\n",
      "[ 0.6616905]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0])\n",
    "b = np.array([1])\n",
    "#test[(i) % 6] = 1\n",
    "ntm.step_forward(a)\n",
    "print ntm.step_forward(b)\n",
    "\n",
    "a = np.array([1])\n",
    "b = np.array([1])\n",
    "#test[(i) % 6] = 1\n",
    "ntm.step_forward(a)\n",
    "print ntm.step_forward(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
